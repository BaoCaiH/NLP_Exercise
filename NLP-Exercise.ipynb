{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "# import sklearn\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: pos\n",
      "text: Let me start by saying at the young age of 34 I was suddenly widowed. I was devastated as he was NOT sick--- he died unexpectedly basically of a coronary--- his carotids blew out-- he died behind our house. There was a lot of speculation from police, cause he fell on something and it bashed his head in. I was a suspect for murder until the autopsy came back.   My children were as traumatized as I was, so in love with a good father figure as he. I had three small children, no education, no financial support. I took it very, very hard.   Within two years my in-laws attacked me verbally, physically, emotionally and spiritually demanding I grieve not in front of the children, and put on masks and showed people what they wanted to see, not show them my pain during holidays... Nobody stood up for me and my choice to sit out one holiday, except of course, the grief therapist I was seeing that had advised me to follow my heart and soul. My in-laws didn't get it! It changed FOREVER my relationship with them, and I have never been back for a holiday. This is only one example of how my grief was disrespected! My own (new) husband has seen me fall apart talking about the trauma when I shared from my soul. I collapse, can not breathe, hyperventilate, and generally am defunct for a few days if I even try to convey the hidden pain.   Now about this movie...  Today, my soul was stirred, my heart broken. My fears and pain re-surfaced from the real demons this movie presents; how one grieves compared to how others expect us too and the demons within. Adam Sandler portrayed perfectly the horrendous agony you face, overcome and most of all, work through on your own time! This movie dredged up all the pain that I have tried over the years to deal with. You see, when something harms your soul so profoundly, so deep that utterances are all that come from your mouth in moments of thinking, you can not deal with it without wishing you were dead and walking through life, in a dead state.   The bible has a scripture, Romans 8:26 that I have clung to, that when my mouth and soul know not what to pray for, that God's Holy Spirit carries that agony to the feet of God-- I need not speak. Sandler portrayed that to perfection!   There is a scene where he has been hauled into a court hearing, for mental health commitment purposes, and he goes back in to face his in-laws--- (familiar to me)--- and he tells them the stunning truths that he has been possessed by, per Se, that he can't get over. It's a profoundly strong, and mighty performance. I started bawling and had a hard time after wards getting up to walk out from the theater feeling my legs too weak to do so. My son was with me and saw it first hand, my precise motions while trying to hold it all together; a lesson for him, my youngest who barely remembers his daddy. It's been 13 years for me but this movie brought me back to the moment of losing my in-laws forever when they demanded a mask on my emotions and my surrendering to their desires, instead of respect to my own.   I write this, so that if you are a griever, you are prepared for this movie, but recommend it highly in the 1000 star performance Sandler gave.   If you are not yet a griever, please take a lesson from his movie and just listen and accept people's choices in their grief, letting them find peace in their own time! Sometimes, the soul can not utter the words to convey our pain.   Go see this movie with tissues and not without preparing to take it in... to your soul!\n"
     ]
    }
   ],
   "source": [
    "with open('Data/imdb_train.json') as f:\n",
    "    data = json.load(f)\n",
    "random.shuffle(data)\n",
    "print('class label:', data[0]['class'])\n",
    "print('text:', data[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many texts 25000\n",
      "This many labels 25000\n",
      "\n",
      "pos Let me start by saying at the young age of 34 I wa...\n",
      "pos I saw this film when it was originally released in...\n",
      "neg This early role for Barbara Shelley(in fact,her fi...\n",
      "pos A DOUBLE LIFE has developed a mystique among film ...\n",
      "neg Grand Central Murder (1942) Dir: S. Sylvan Simon  ...\n",
      "pos Anna (Ursula Andress) is brought in as an official...\n",
      "neg Jean Rollin artistic nonsense about vampires, alie...\n",
      "neg The Egyptian Movies has A Lot Of Filmes With High ...\n",
      "pos I first saw this film during and International Fil...\n",
      "neg The good thing about this that's at least fresh: A...\n",
      "pos My definition of a great movie is if you want to c...\n",
      "pos This movie is sort of a Carrie meets Heavy Metal. ...\n",
      "pos I don't understand the low 5.7 rating on this film...\n",
      "neg i saw this movie at the toronto film festival with...\n",
      "neg Even if 99,99% of people that has seen this movie ...\n",
      "neg French director Jean Rollin isn't exactly known fo...\n",
      "neg I can't believe it that was the worst movie i have...\n",
      "neg The film is severely awful and is demeaning to rap...\n",
      "neg What the hell is this? \\Kooky drama\\\"? \\\"Lawyers i...\n",
      "pos Los Angeles TV news reporter Jennifer (the beautif...\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts and labels into separate lists\n",
    "texts = [one_example['text'] for one_example in data]\n",
    "labels = [one_example['class'] for one_example in data]\n",
    "print('This many texts', len(texts))\n",
    "print('This many labels', len(labels))\n",
    "print()\n",
    "for label, text in list(zip(labels, texts))[:20]:\n",
    "    print(label, text[:50]+'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique features:\n",
      "['an', 'and', 'auto', 'build', 'compiler', 'completion', 'documentation', 'editor', 'error', 'formatter', 'friendly', 'great', 'has', 'inspections', 'integrated', 'manager', 'messages', 'more', 'multi', 'notch', 'package', 'rust', 'smart', 'support', 'tool', 'tooling', 'top', 'type', 'useful', 'with']\n",
      "\n",
      "Feature vectors (sparse format):\n",
      "  (0, 21)\t0.5\n",
      "  (0, 12)\t0.5\n",
      "  (0, 11)\t0.5\n",
      "  (0, 6)\t0.5\n",
      "  (1, 29)\t0.3393931489111758\n",
      "  (1, 28)\t0.4206690600631704\n",
      "  (1, 16)\t0.4206690600631704\n",
      "  (1, 10)\t0.4206690600631704\n",
      "  (1, 8)\t0.4206690600631704\n",
      "  (1, 4)\t0.4206690600631704\n",
      "  (2, 26)\t0.3094185760868625\n",
      "  (2, 25)\t0.3094185760868625\n",
      "  (2, 24)\t0.3094185760868625\n",
      "  (2, 20)\t0.3094185760868625\n",
      "  (2, 19)\t0.3094185760868625\n",
      "  (2, 15)\t0.3094185760868625\n",
      "  (2, 14)\t0.3094185760868625\n",
      "  (2, 3)\t0.3094185760868625\n",
      "  (2, 1)\t0.41444245308083316\n",
      "  (2, 0)\t0.2496369589290994\n",
      "  (3, 29)\t0.27274066223567134\n",
      "  (3, 27)\t0.3380550208269348\n",
      "  (3, 23)\t0.3380550208269348\n",
      "  (3, 22)\t0.3380550208269348\n",
      "  (3, 18)\t0.3380550208269348\n",
      "  (3, 13)\t0.3380550208269348\n",
      "  (3, 7)\t0.3380550208269348\n",
      "  (3, 5)\t0.3380550208269348\n",
      "  (3, 2)\t0.27274066223567134\n",
      "  (3, 1)\t0.22639938732779208\n",
      "  (4, 17)\t0.5163739676148649\n",
      "  (4, 9)\t0.5163739676148649\n",
      "  (4, 2)\t0.4166072657167828\n",
      "  (4, 1)\t0.345821664219199\n",
      "  (4, 0)\t0.4166072657167828\n"
     ]
    }
   ],
   "source": [
    "# Check what's the different between count and tfidf\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "toy_data = [\n",
    "    'Rust has great documentation, ',\n",
    "    'a friendly compiler with useful error messages, ',\n",
    "    'and top-notch tooling â€” an integrated package manager and build tool, ',\n",
    "    'smart multi-editor support with auto-completion and type inspections, ',\n",
    "    'an auto-formatter, and more.'\n",
    "]\n",
    "\n",
    "vectorizer.fit(toy_data)\n",
    "print('Unique features:')\n",
    "print(vectorizer.get_feature_names())\n",
    "print()\n",
    "print('Feature vectors (sparse format):')\n",
    "print(vectorizer.transform(toy_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each features are assigned a idf score instead of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape = (25000, 74849)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=100000, binary=False, ngram_range=(1,1))\n",
    "feature_matrix = vectorizer.fit_transform(texts)\n",
    "print('Feature matrix shape =',feature_matrix.shape)\n",
    "# print('what did we get? ->', feature_matrix.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 51457)\t0.04795948269660875\n",
      "  (0, 67057)\t0.05828874426187375\n",
      "  (0, 27863)\t0.019126160505820496\n",
      "  (0, 73608)\t0.03037829896863956\n",
      "  (0, 70576)\t0.039126420735074566\n",
      "  (0, 61641)\t0.028697483883389954\n",
      "  (0, 48881)\t0.0407498222468267\n",
      "  (0, 24629)\t0.020591401067233558\n",
      "  (0, 38490)\t0.04237831268558244\n",
      "  (0, 12161)\t0.04134737345928831\n",
      "  (0, 1408)\t0.03791460497341077\n",
      "  (0, 38986)\t0.036841561749160374\n",
      "  (0, 35787)\t0.012789468545365537\n",
      "  (0, 65333)\t0.04289867769951406\n",
      "  (0, 50365)\t0.029766017385358074\n",
      "  (0, 74216)\t0.023334519117508362\n",
      "  (0, 26959)\t0.028238203698170868\n",
      "  (0, 62848)\t0.02566885143203882\n",
      "  (0, 41)\t0.05042454051588808\n",
      "  (0, 30923)\t0.028521634844574706\n",
      "  (0, 54079)\t0.025762869793363345\n",
      "  (0, 51454)\t0.041142358035526086\n",
      "  (0, 28663)\t0.14330459040716995\n",
      "  (0, 73827)\t0.03220118565410733\n",
      "  (0, 55262)\t0.03421725222648945\n",
      "  :\t:\n",
      "  (24999, 66474)\t0.04436442968220257\n",
      "  (24999, 72703)\t0.02323894415788135\n",
      "  (24999, 52709)\t0.041748138871704844\n",
      "  (24999, 68769)\t0.03161098636688963\n",
      "  (24999, 71159)\t0.02488867721972075\n",
      "  (24999, 61038)\t0.04654337462806434\n",
      "  (24999, 73342)\t0.03284643839286079\n",
      "  (24999, 39562)\t0.03289737285568453\n",
      "  (24999, 61380)\t0.02124549160666755\n",
      "  (24999, 12053)\t0.0996332699426923\n",
      "  (24999, 25450)\t0.01613734684207269\n",
      "  (24999, 33004)\t0.05445083009295636\n",
      "  (24999, 34683)\t0.01347906767945856\n",
      "  (24999, 3258)\t0.0749998522491504\n",
      "  (24999, 46916)\t0.053111942316089206\n",
      "  (24999, 66432)\t0.02220787286258282\n",
      "  (24999, 31095)\t0.06711268809714503\n",
      "  (24999, 46050)\t0.03662447577934446\n",
      "  (24999, 30211)\t0.022737478576431824\n",
      "  (24999, 4465)\t0.017394821702109108\n",
      "  (24999, 72196)\t0.0867981211107455\n",
      "  (24999, 46680)\t0.038161772049438145\n",
      "  (24999, 66339)\t0.18284004326310238\n",
      "  (24999, 9962)\t0.02124549160666755\n",
      "  (24999, 41798)\t0.026901323955618357\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68213)\n",
      "(5000, 68213)\n"
     ]
    }
   ],
   "source": [
    "# With Validation\n",
    "# train_text_set, test_texts, train_label_set, test_labels = train_test_split(\n",
    "#     texts, labels,\n",
    "#     test_size=0.2, random_state=4\n",
    "# )\n",
    "# train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "#     train_text_set, train_label_set,\n",
    "#     test_size=0.2, random_state=4\n",
    "# )\n",
    "\n",
    "# Without Validation\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels,\n",
    "    test_size=0.2, random_state=4\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100000,\n",
    "    binary=True,\n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "\n",
    "feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "feature_matrix_test = vectorizer.transform(test_texts)\n",
    "\n",
    "print(feature_matrix_train.shape)\n",
    "print(feature_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0005, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearSVC(\n",
    "    C=0.0005,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    feature_matrix_train,\n",
    "    train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score 0.8368\n",
      "Train set score: 0.84805\n"
     ]
    }
   ],
   "source": [
    "print('Test set score',classifier.score(feature_matrix_test, test_labels))\n",
    "print('Train set score:',classifier.score(feature_matrix_train, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same parameters in the `vectorizer` and the `svm`, vectorizing the string by *idf* score probably gave the `svm` more information so it's less forgiving in classifying task. Next, I'll use `GridSearch` to alter `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            'vectorize',\n",
    "            CountVectorizer(\n",
    "                max_features=100000,\n",
    "                binary=True,\n",
    "                ngram_range=(1,1)\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            'classify',\n",
    "            LinearSVC(\n",
    "                verbose=1\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_tfidf = {\n",
    "    'vectorize__ngram_range': [\n",
    "        (1, 1),\n",
    "        (1, 2),\n",
    "        (2, 2),\n",
    "        (1, 3),\n",
    "        (2, 3)\n",
    "    ],\n",
    "    'classify__C': np.logspace(\n",
    "        -4, 4, 5\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tfidf = GridSearchCV(\n",
    "    pipe_tfidf,\n",
    "    grid_param_tfidf,\n",
    "    cv=5,\n",
    "    n_jobs=4,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 125 out of 125 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorize',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=True,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=100000,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=No...\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=1))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'classify__C': array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
       "                         'vectorize__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                    (1, 3), (2, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tfidf.fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combination is as follow:\n",
      "SVC : 0.01\n",
      "tfidf ram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('The best combination is as follow:')\n",
    "for param, value in grid_tfidf.best_params_.items():\n",
    "    if 'vectorize' in param:\n",
    "        print('tfidf {}: {}'.format(param[13:], value))\n",
    "    else:\n",
    "        print('SVC {}: {}'.format(param[12:], value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tfidf.best_estimator_.score(test_texts, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
